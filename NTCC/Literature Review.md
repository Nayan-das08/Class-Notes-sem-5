>Chapter - [[_NTCC 2nd yr]]

# Literature Review

## Lagaris et. al.
One of the earliest and most influential papers on the problem of solving IVP and BVP for Ordinary and Partial Differential Equations with the help of Neural Networks is Lagaris et. al., where the authors present it as a optimization problem. they proposed that the difference between the differential of the solution and the function definition of the differential operator be minimized over discrete values of domain set. The initial and boundary condition components were added separately to the trial solution formula to train the model. They preferred a Quasi-Newton BFGS algorithm to optimize the loss function, which was chosen by Raissi et. al. as well. They presented the accuracy of the predicted solution with comparison to Finite Element Method (FEM), a numerical method for solving PDEs. One of the most important feature of this approach is that there is no need for any labelled dataset containing solutions of differential equations at various points as this model gets its set of actual solutions from the function defining the differential.

## Raissi et. al.
Another paper that took the field to new levels was Raissi et. al. where they proposed a Physics Informed Neural Network, a supervised learning approach where an ANN model which is capable of solving any PDE while respecting the laws established by it. It exploits the Universal Approximation Theorem and the concept of automatic differentiation. They obtain a dataset using spectral methods to solve the PDEs. The main goal is to optimize the loss function which is a combination of several terms of Mean Squared Error concerning various points over the domain. These terms include error of solutions predicted by the model at the initial condition, boundary conditions and the function giving the physical information in the form of the value of differential equation at various points of training set. They have tabulated error with respect to number of points used for supervised learning and number of collocation points used for minimizing the differential equation function. The examples of PDEs used to demonstrate the approach are Burgers' Equation and Schrodinger's equation.

## Raissi
The same approach was proposed by Raissi in another paper where the model was implemented for some other examples of Burgers' Equation and Korteweg-de Vries equation, Kuramoto-Sivashinsky equation, Nonlinear Schrodinger equation. The author also proposed its applications in stochastic partial differential equations and Geostationary Operational Environmental Satellites (GOES) data concerning seas surface temperatures.

## applications
Among some of the published applications of PINN approach proposed by Raissi et.al. the ones referred are Moseley et. al. where the authors implement the PINN model on 2D acoustic wave equation. They obtain the data from Finite Difference Method (FDM). They test the model for different values of governing parameters like density and velocity. Although with the help of this model they were able to infer physical phenomena like transmission, reflection, compression and expansion of waves in various interfaces, they observed a limitation: the PINN models needs to be trained again for any new set of constraints. Another instance of implementation of PINN for wave equations is Guo et. al. where they tested this for 1D wave equation, Korteweg-de Vries equation and KdV-Burgers equation and achieved good results. 

Among other applications, Rao et. al. have presented a PINN model for solving elastodynamics problems without the use of any labelled data. They propose a mixed variable scheme for their framework and this has proven to be quite successful as it significantly increased the accuracy and learning capabilities of the model. They performed test on a plate under tension, and several 2D wave propagation on various boundaries.

There have been success in other approaches which do not concern PINN approach. This includes a comprehensive study by Beck et. al. where several different Deep Learning based approximation techniques for linear and non-linear PDEs are presented. Another paper by Sirignano et. al. which presents a Deep Learning Algorithm - DGM for solving PDE greatly resembles Lagaris et. al. and Raissi et. al. approaches. Along with that the paper also presents a series of numercal methods for solving Differential Equations, like a more computationally cheaper Monte-Carlo approximation for second derivative. They test their algorithm on High-dimensional Hamilton-Jacobi-Bellman PDE, Burgers’ equation and discusses other Neural Network approximation theorems. 

There are several environments available for scientific computing and for solving Differential Equations. Now, there are packages being developed for existing and popular Neural Network environments. One among these is SciANN, introduced by Haghighat et. al. at Massachusetts Institute of Technology, Cambridge. This package provides for scientific computing and more specifically, Physics Informed Deep Learning. It works as a wrapper over Google's Tensorflow and François Chollet's Keras.  